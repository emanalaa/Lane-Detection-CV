{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_members_names = ['إسراء ياسر ابوالقاسم',\n",
    "                      'ايمان علاء فرج كامل',\n",
    "                      'منة الله مصطفى مصطفى عوض',\n",
    "                      'منة محيي الدين محمود',\n",
    "                      'ميرنا محمد يسري']\n",
    "team_members_seatnumbers = ['2016170080',\n",
    "                            '2016170113'\n",
    "                            '2016170437',\n",
    "                            '2016170438',\n",
    "                            '2016170450']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from scipy import interpolate\n",
    "from PIL import Image, ImageDraw\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import math "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Conversion and Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rbg_to_grayscale(img):\n",
    "    # This function will do color transform from RGB to Gray\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rgb_to_hsv(img):\n",
    "    # This function will do color transform from RGB to HSV\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_thresholding(img, low_threshold, high_threshold):\n",
    "    # define the fixed values of the pixels\n",
    "    strong = 255\n",
    "    outimg = np.zeros((img.shape[0],img.shape[1]))\n",
    "\n",
    "    # extract the indices of the pixels per condition for each channel\n",
    "    in_i, in_j, in_ch = np.where((low_threshold <= img & (img <= high_threshold)))\n",
    "    irrelevant_i, irrelevant_j, irrelevant_ch = np.where((img < low_threshold) | (img > high_threshold))\n",
    "\n",
    "    # update the indices with the corresponding pixel value\n",
    "    outimg[in_i, in_j] = strong\n",
    "    outimg[irrelevant_i, irrelevant_j] = 0\n",
    "\n",
    "    return outimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(sigma=0.5):\n",
    "    # Specify the kernel size\n",
    "    if sigma > 1:\n",
    "        size = 5\n",
    "    else:\n",
    "        size = 3\n",
    "\n",
    "    # Calculate the formula\n",
    "    size = int(size) // 2\n",
    "    x, y = np.mgrid[-size:size+1, -size:size+1]\n",
    "    normal = 1 / (2.0 * np.pi * sigma**2)\n",
    "    g = normal * np.exp(-((x**2 + y**2) / (2.0*sigma**2)))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_reduction(img):\n",
    "    kernel = gaussian_kernel(1.4)\n",
    "    '''\n",
    "    window_size = kernel.shape[0]\n",
    "    offset = window_size//2\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    # the Filter algorithm\n",
    "    img2 = img.copy()\n",
    "    for i in range(offset, height - offset):\n",
    "        for j in range(offset, width - offset):\n",
    "            new_pixel = 0\n",
    "            for n in range(window_size):\n",
    "                for m in range(window_size):\n",
    "                    a = i - offset + n\n",
    "                    b = j - offset + m\n",
    "                    new_pixel += img[a, b] * kernel[n, m]\n",
    "            img2[i, j] = new_pixel\n",
    "    '''\n",
    "    img = ndimage.filters.convolve(img, kernel)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_calculation(img):\n",
    "    Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
    "    Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=np.float32)\n",
    "\n",
    "    Ix = ndimage.filters.convolve(img, Kx)\n",
    "    Iy = ndimage.filters.convolve(img, Ky)\n",
    "\n",
    "    G = np.hypot(Ix, Iy)\n",
    "    G = G / G.max() * 255\n",
    "    theta = np.arctan2(Iy, Ix)\n",
    "\n",
    "    G = G.astype(int)\n",
    "    return G, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(img, theta):\n",
    "    height, width = img.shape\n",
    "    out = np.zeros((height, width), dtype=int)\n",
    "    # Change from radian to degree\n",
    "    angle = theta * 180 / np.pi\n",
    "    angle[angle < 0] += 180\n",
    "\n",
    "    for i in range(1, height-1):\n",
    "        for j in range(1, width-1):\n",
    "            point_1 = 255\n",
    "            point_2 = 255\n",
    "\n",
    "            # Angle 0°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (east and west) directions\n",
    "            if (0 <= angle[i, j] < 22.5) or (157.5 <= angle[i, j] <= 180):\n",
    "                point_1 = img[i, j-1]\n",
    "                point_2 = img[i, j+1]\n",
    "            # Angle 45°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (north east and south west) directions.\n",
    "            elif 22.5 <= angle[i, j] < 67.5:\n",
    "                point_1 = img[i-1, j+1]\n",
    "                point_2 = img[i+1, j-1]\n",
    "            # Angle 90°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (north and south) directions.\n",
    "            elif 67.5 <= angle[i, j] < 112.5:\n",
    "                point_1 = img[i-1, j]\n",
    "                point_2 = img[i+1, j]\n",
    "            # Angle 135°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (north west and south-east) directions.\n",
    "            elif 112.5 <= angle[i, j] < 157.5:\n",
    "                point_1 = img[i-1, j-1]\n",
    "                point_2 = img[i+1, j+1]\n",
    "\n",
    "            # if the pixel's value is the maximum then update the out, otherwise leave it with value = 0\n",
    "            if (img[i, j] >= point_1) and (img[i, j] >= point_2):\n",
    "                out[i, j] = img[i, j]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_thresholding(img, low_threshold=2, high_threshold=25):\n",
    "    # define the fixed values of the pixels\n",
    "    weak = 25\n",
    "    strong = 255\n",
    "\n",
    "    # extract the indices of the pixels per condition\n",
    "    strong_i, strong_j = np.where(img >= high_threshold)\n",
    "    weak_i, weak_j = np.where((low_threshold <= img) & (img <= high_threshold))\n",
    "    irrelevant_i, irrelevant_j = np.where(img < low_threshold)\n",
    "\n",
    "    # update the indices with the corresponding pixel value\n",
    "    img[strong_i, strong_j] = strong\n",
    "    img[weak_i, weak_j] = weak\n",
    "    img[irrelevant_i, irrelevant_j] = 0\n",
    "\n",
    "    return img, weak, strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hysteresis_edge_tracking(img, weak, strong):\n",
    "    height, width = img.shape\n",
    "    # Get the indices of the weak pixels\n",
    "    weak_i, weak_j = np.where(img == weak)\n",
    "    for (i, j) in zip(weak_i, weak_j):\n",
    "        if i == 0 or j == 0 or i == height - 1 or j == width - 1:\n",
    "            continue\n",
    "        # Check if any of the  8-connected neighborhood pixels is a strong pixel\n",
    "        if np.any(np.where(img[i-1:i+2, j-1:j+2] == strong)):\n",
    "            img[i, j] = strong\n",
    "        # If not, then suppress the weak pixel\n",
    "        else:\n",
    "            img[i, j] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function, to reduce the redundant\n",
    "# plotting code\n",
    "def plotting(img, fig_num, title):\n",
    "    plt.figure(fig_num)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges_canny(img, low_threshold=2, high_threshold=50):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        :param img: np.ndarray((height, width)), gray-image\n",
    "        :param low_threshold: an integer\n",
    "        :param high_threshold: an integer\n",
    "    :return: edges image\n",
    "    \"\"\"\n",
    "    img = img.copy()\n",
    "\n",
    "    # 1. Noise reduction\n",
    "    # using Gaussian Smoothing Kernel\n",
    "    img = noise_reduction(img)\n",
    "    #plotting(img, 1, 'Gaussian Filter')\n",
    "\n",
    "    # 2. Gradient Calculations\n",
    "    # using Sobel kernels\n",
    "    img, theta = gradient_calculation(img)\n",
    "    #plotting(img, 2, 'Sobel Filter (G)')\n",
    "\n",
    "    # 3. Non-Maximum Suppression\n",
    "    img = non_max_suppression(img, theta)\n",
    "    #plotting(img, 3, 'Non-Maximum Suppression')\n",
    "\n",
    "    # 4. Double Thresholding\n",
    "    img, weak, strong = double_thresholding(img, low_threshold, high_threshold)\n",
    "    #plotting(img, 4, 'Double Thresholding')\n",
    "\n",
    "    # 5. Edge Tracking by Hysteresis\n",
    "    img = hysteresis_edge_tracking(img, weak, strong)\n",
    "    #plotting(img, 5, 'Edge Tracking by Hysteresis')\n",
    "\n",
    "    #plt.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Guassian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(img, kernel_size, width, height):\n",
    "    # You should implement Gaussian Noise Removal Here\n",
    "    #Mean_filter\n",
    "    #height = img.shape(0)\n",
    "    #width = img.shape(1)\n",
    "    final_image = img.copy()\n",
    "    mask_one_dim = math.sqrt(kernel_size)\n",
    "    offset = int(mask_one_dim // 2)\n",
    "    for i in range(offset, height - offset):\n",
    "        for j in range(offset, width - offset):\n",
    "            sum = 0\n",
    "            for r in range(i - offset, i + offset + 1):\n",
    "                for c in range(j - offset, j + offset + 1):\n",
    "                    sum += img[r][c]\n",
    "            final_image[i][j] = sum // kernel_size\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_image(img, vertices, width, height):\n",
    "    out_img = img.copy();\n",
    "    # Mask out the pixels outside the region defined in vertices (set the color to black)\n",
    "    #height = img.shape(0)\n",
    "    #width = img.shape(1)\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "            if vertices[i][j] == 0:\n",
    "                out_img[i][j] = 0\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Hough transform to find the lanes\n",
    "# Input:\n",
    "#   img - numpy array: binary image containing the edges after applying Canny Detector\n",
    "# Output:\n",
    "#   lines - list of list: list of lines, each line = [x1, y1, x2, y2]\n",
    "def hough_transform(img, accepted_ratio=0.5, rho_step=1, theta_step=1):\n",
    "    print('\\nHough Transform in progress')\n",
    "    # Calculating diagonal length of the image to define the range of the rhos\n",
    "    height, width = img.shape\n",
    "    diagonal_length = round(math.sqrt(height ** 2 + width ** 2))\n",
    "    rhos = np.arange(-diagonal_length, diagonal_length, step=rho_step)\n",
    "\n",
    "    # Setting the thetas and their cosines/sines\n",
    "    thetas = np.arange(-90.0, 90.0, step=theta_step)\n",
    "    cos_thetas = np.cos(np.deg2rad(thetas))\n",
    "    sin_thetas = np.sin(np.deg2rad(thetas))\n",
    "\n",
    "    accumulator = np.zeros((len(rhos), len(thetas)))\n",
    "\n",
    "    edge_pts_ys, edge_pts_xs = np.nonzero(img)\n",
    "    for i in trange(len(edge_pts_xs)):\n",
    "        x = edge_pts_xs[i]\n",
    "        y = edge_pts_ys[i]\n",
    "        for theta_idx in range(len(thetas)):\n",
    "            rho = x * cos_thetas[theta_idx] + y * sin_thetas[theta_idx]\n",
    "            rho_idx = np.argmin(np.abs(rhos - rho))  # find the index of the closest rho to the computed rho\n",
    "            accumulator[rho_idx, theta_idx] += 1\n",
    "\n",
    "    # lines_rhos = []\n",
    "    # lines_thetas = []\n",
    "    lines_rhos_indices, lines_thetas_indices = np.nonzero(accumulator >= accumulator.max() * accepted_ratio)\n",
    "    lines = []\n",
    "    for i in range(len(lines_rhos_indices)):\n",
    "        rho_idx = lines_rhos_indices[i]\n",
    "        rho = rhos[rho_idx]\n",
    "        # lines_rhos.append(rho)\n",
    "\n",
    "        theta_idx = lines_thetas_indices[i]\n",
    "        theta = thetas[theta_idx]\n",
    "        # lines_thetas.append(theta)\n",
    "\n",
    "        a = cos_thetas[theta_idx]\n",
    "        b = sin_thetas[theta_idx]\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 10000 * (-b))\n",
    "        y1 = int(y0 + 10000 * a)\n",
    "        x2 = int(x0 - 10000 * (-b))\n",
    "        y2 = int(y0 - 10000 * a)\n",
    "        lines.append([x1, y1, x2, y2])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hough_lines(img, lines, path, color=[255, 0, 0], thickness=8):\n",
    "    d = ImageDraw.Draw(img)\n",
    "    for line in lines:\n",
    "        #d.line(line, fill=(255, 255, 255), width=thickness)\n",
    "        d.line(line, fill=(color[0], color[1], color[2]), width=thickness)\n",
    "    #img.save(path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_test():\n",
    "    input_image = read_image('hough_test_1.jpg')\n",
    "    edges = detect_edges_canny(input_image, 2, 50)\n",
    "    lines = hough_transform(edges, 0.3)\n",
    "    draw_hough_lines(Image.open('hough_test_1.jpg'), lines, 'hough_test_1_out.jpg')\n",
    "\n",
    "    input_image = read_image('hough_test_2.jpg')\n",
    "    edges = detect_edges_canny(input_image, 2, 50)\n",
    "    lines = hough_transform(edges)\n",
    "    draw_hough_lines(Image.open('hough_test_2.jpg'), lines, 'hough_test_2_out.jpg')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Lane Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_length(line):\n",
    "    x1, y1, x2, y2 = line\n",
    "    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = mx + b\n",
    "# This function returns the slope (m) and the intercept (b) of the input line.\n",
    "def get_line_slope_intercept(line):\n",
    "    x1, y1, x2, y2 = line\n",
    "    if x2 - x1 == 0:\n",
    "        return math.inf, 0\n",
    "    slope = (y2 - y1) / (x2 - x1)\n",
    "    # b = y - mx\n",
    "    intercept = slope * x1 - y1\n",
    "    return slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The upper left corner of the image is (0, 0)\n",
    "# X increases top-down\n",
    "# Y increase left-right\n",
    "# Left line: as Y increases, X decreases, so it has a negative slope\n",
    "# Right line: as Y increase, X increases, so it has a positive slope\n",
    "\n",
    "# Input: a list of lines, where each line = [x1, y1, x2, y2]\n",
    "# Output: avg_of_left_lines, avg_of_right_lines, each is a tuple(avg_slope, avg_intercept)\n",
    "def get_avg_slope_intercept(lines):\n",
    "    right_lines = []\n",
    "    right_lengths = []\n",
    "    left_lines = []\n",
    "    left_lengths = []\n",
    "    for line in lines:\n",
    "        slope, intercept = get_line_slope_intercept(line)\n",
    "        if slope == math.inf:\n",
    "            continue\n",
    "        line_length = get_line_length(line)\n",
    "        if slope < 0: # left line\n",
    "            left_lines.append((slope, intercept))\n",
    "            left_lengths.append(line_length)\n",
    "        else:         # right line\n",
    "            right_lines.append((slope, intercept))\n",
    "            right_lengths.append(line_length)\n",
    "    \n",
    "    \n",
    "    # Weighted average of all right lines\n",
    "    if len(right_lines) > 0:\n",
    "        element_wise_mul = length * line for length, line in zip(right_lengths, right_lines)\n",
    "        avg_of_right_lines = element_wise_mul / np.sum(right_lengths)\n",
    "    else:\n",
    "        avg_of_right_lines = None\n",
    "    \n",
    "    # Weighted average of all left lines \n",
    "    if len(left_lines) > 0:\n",
    "        element_wise_mul = length * line for length, line in zip(left_lengths, leftt_lenghts)\n",
    "        avg_of_left_lines = np.dot(left_lengths * left_lines) / np.sum(left_lengths)\n",
    "    else:\n",
    "        avg_of_left_lines = None\n",
    "    \n",
    "    return avg_of_right_lines, avg_of_left_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: y1, y2, line in the form (slope, intercept)\n",
    "# Output: line in the form [x1, y1, x2, y2]\n",
    "# y = mx + b, x = (y - b) / m\n",
    "def get_line_endpoints(y1, y2, line):\n",
    "    slope, intercept = line\n",
    "    x1 = int((y1 - intercept) / slope)\n",
    "    x2 = int((y2 - intercept) / slope)\n",
    "    return [x1, y1, x2, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hough returns a lot of lines for one lane line, so we average them to have one line per lane line.\n",
    "def get_lane_lines(img, lines):\n",
    "    avg_of_left_lines, avg_of_right_lines = get_avg_slope_intercept(lines)\n",
    "    y1 = img.shape[0] \n",
    "    y2 = img.shape[0] * 0.6\n",
    "    left_lane = get_line_endpoints(y1, y2, avg_of_left_lines)\n",
    "    right_lane = get_line_endpoints(y1, y2, avg_of_right_lines)\n",
    "    return left_lane, right_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines_connected(img, hough_lines, color=[255, 0, 0], thickness=8):\n",
    "    # This function should draw lines to the images (default color is red and thickness is 8)\n",
    "    lane_lines = get_lane_lines(img, hough_lines)\n",
    "    image_with_line = img\n",
    "    for line in lane_lines:\n",
    "        point_one = (int(line[0]), int(line[1]))\n",
    "        print(point_one)\n",
    "        point_two = (int(line[2]), int(line[3]))\n",
    "        print(point_two)\n",
    "        image_with_line = cv2.line(image_with_line, point_one, point_two, color, thickness)\n",
    "    cv2.imshow(\"image with lines\",image_with_line)\n",
    "    cv2.waitKey(0)\n",
    "    return image_with_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-3017ce5b56b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "x, y = []\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(img_path):\n",
    "    img = mpimg.imread('lanes_test.jpg')\n",
    "    #img = Image.open(img_path)\n",
    "    #img = img.convert(\"L\")\n",
    "    #img = np.asarray(img, dtype=int)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    return video, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frames(video):\n",
    "    frames = []\n",
    "    width = video.get(3)\n",
    "    height = video.get(4)\n",
    "    success, frame = video.read()\n",
    "    while success:\n",
    "        frames.append(frame)\n",
    "        success, frame = video.read()\n",
    "    return frames, int(width), int(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_video(pathOut, frames, fps, width, height):\n",
    "    size = (width, height)\n",
    "\n",
    "    out = cv2.VideoWriter(pathOut, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pipeline(image, width, height):\n",
    "    # 1. read the image\n",
    "    # 2. convert to HSV\n",
    "    hsv_img = convert_rgb_to_hsv(image)\n",
    "        \n",
    "    # 3. convert to Gray\n",
    "    gray_img = convert_rbg_to_grayscale(image)\n",
    "        \n",
    "    # 4. Threshold HSV for Yellow and White (combine the two results together)\n",
    "        \n",
    "    # 4.1 Threshold HSV for Yellow\n",
    "    lower = np.uint8([10, 0, 200])\n",
    "    upper = np.uint8([40, 255, 255])\n",
    "    yellow_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "    # 4.1 Threshold HSV for White\n",
    "    lower = np.uint8([0, 0, 200])\n",
    "    upper = np.uint8([255, 55, 255])\n",
    "    white_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "    # 4.1 Combine the resuls together\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "\n",
    "    # 5. Mask the gray image using the threshold output from step 4\n",
    "    masked_gray_img = mask_image(gray_img, mask, width, height)\n",
    "\n",
    "    # 6. Apply noise remove (gaussian) to the masked gray image\n",
    "    masked_gray_img = remove_noise(masked_gray_img, 3, width, height)\n",
    "\n",
    "    # 7. use canny detector and fine tune the thresholds (low and high values)\n",
    "    # TODO: masked_gray_img should be of data-type numpy.ndarray\n",
    "    canny_out_img = detect_edges_canny(masked_gray_img, low_threshold=2, high_threshold=50)\n",
    "\n",
    "    # 8. mask the image using the canny detector output\n",
    "    masked_with_canny = mask_image(masked_gray_img, canny_out_img, width, height)\n",
    "\n",
    "    # 9. apply hough transform to find the lanes\n",
    "    lines_for_drawing = hough_transform(masked_with_canny)\n",
    "\n",
    "    # 10. apply the pipeline you developed to the challenge videos\n",
    "    image_with_lines = draw_lines_connected(image, lines_for_drawing)\n",
    "\n",
    "    return image_with_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_pipeline(video_frames, width, height, fps):\n",
    "\n",
    "    new_video_frames = []\n",
    "    i = 1\n",
    "    for frame in video_frames:\n",
    "        new_frame = image_pipeline(frame, width, height)\n",
    "        new_video_frames.append(new_frame)\n",
    "        print(\"{} done!\".format(i))\n",
    "        i+=1\n",
    "        if i == 25:\n",
    "            break\n",
    "\n",
    "    print(\"Length of frames = \", len(new_video_frames))\n",
    "    write_video(\"ChallengeWithLines.mp4\", new_video_frames, 0, width, height)\n",
    "    print(\"Video saved succesffuly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of frames =  0\n",
      "Video saved succesffuly\n"
     ]
    }
   ],
   "source": [
    "#MAIN\n",
    "video, fps = read_video(\"Challenge.mp4\")\n",
    "video_frames, width, height = get_video_frames(video)\n",
    "video_pipeline(video_frames, width, height, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = read_image('lanes_test.jpg')\n",
    "width = 960\n",
    "height = 540\n",
    "hsv_img = convert_rgb_to_hsv(image)\n",
    "        \n",
    "# 3. convert to Gray\n",
    "gray_img = convert_rbg_to_grayscale(image)\n",
    "        \n",
    "# 4. Threshold HSV for Yellow and White (combine the two results together)\n",
    "        \n",
    "# 4.1 Threshold HSV for Yellow\n",
    "lower = np.uint8([10, 0, 100])\n",
    "upper = np.uint8([40, 255, 255])\n",
    "yellow_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "# 4.1 Threshold HSV for White\n",
    "lower = np.uint8([0, 200, 0])\n",
    "upper = np.uint8([200, 255, 255])\n",
    "white_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "# 4.1 Combine the resuls together\n",
    "mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "\n",
    "# 5. Mask the gray image using the threshold output from step 4\n",
    "masked_gray_img = mask_image(gray_img, mask, width, height)\n",
    "\n",
    "# 6. Apply noise remove (gaussian) to the masked gray image\n",
    "masked_gray_img_no_noise = remove_noise(masked_gray_img, 3, width, height)\n",
    "\n",
    "# 7. use canny detector and fine tune the thresholds (low and high values)\n",
    "# TODO: masked_gray_img should be of data-type numpy.ndarray\n",
    "canny_out_img = detect_edges_canny(masked_gray_img_no_noise, low_threshold=10, high_threshold=50)\n",
    "\n",
    "# 8. mask the image using the canny detector output\n",
    "masked_with_canny = mask_image(masked_gray_img_no_noise, canny_out_img, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('yello_mask', yellow_mask)\n",
    "cv2.imshow('white_mask', white_mask)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('gray_img', gray_img)\n",
    "cv2.imshow('masked_img', masked_gray_img)\n",
    "cv2.imshow('Diff between gray and masked gray', gray_img - masked_gray_img)\n",
    "cv2.imshow('masked_img_no_noise', masked_gray_img_no_noise)\n",
    "cv2.imshow('masked_with_canny', masked_with_canny)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 20/17632 [00:00<01:31, 192.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hough Transform in progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 17632/17632 [01:49<00:00, 161.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# 9. apply hough transform to find the lanes\n",
    "hough_lines = hough_transform(masked_with_canny, rho_step = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-0548407d1b8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 10. apply the pipeline you developed to the challenge videos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lanes_test.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimage_with_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_lines_connected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines_for_drawing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-ce32a342423f>\u001b[0m in \u001b[0;36mdraw_lines_connected\u001b[1;34m(img, hough_lines, color, thickness)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdraw_lines_connected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhough_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# This function should draw lines to the images (default color is red and thickness is 8)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlane_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lane_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhough_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mimage_with_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlane_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-e4fbe0fb70dc>\u001b[0m in \u001b[0;36mget_lane_lines\u001b[1;34m(img, lines)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Hough returns a lot of lines for one lane line, so we average them to have one line per lane line.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_lane_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mavg_of_left_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_of_right_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_avg_slope_intercept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-c24c5d06b8ca>\u001b[0m in \u001b[0;36mget_avg_slope_intercept\u001b[1;34m(lines)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mleft_lengths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m         \u001b[1;31m# right line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mright_lines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mright_lengths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "# 10. apply the pipeline you developed to the challenge videos\n",
    "image = read_image('lanes_test.jpg')\n",
    "image_with_lines = draw_lines_connected(image, lines_for_drawing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
