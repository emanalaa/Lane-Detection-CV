{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from scipy import interpolate\n",
    "from PIL import Image, ImageDraw\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_members_names = ['إسراء ياسر ابوالقاسم',\n",
    "                      'منة محيي الدين محمود',\n",
    "                      'ميرنا محمد يسري',\n",
    "                      'منة الله مصطفى مصطفى عوض',\n",
    "                      'ايمان علاء فرج كامل']\n",
    "team_members_seatnumbers = ['2016170080',\n",
    "                            '2016170438',\n",
    "                            '2016170450',\n",
    "                            '2016170437',\n",
    "                            '2016170113']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rbg_to_grayscale(img):\n",
    "    # This function will do color transform from RGB to Gray\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rgb_to_hsv(img):\n",
    "    # This function will do color transform from RGB to HSV\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(sigma=0.5):\n",
    "    # Specify the kernel size\n",
    "    if sigma > 1:\n",
    "        size = 5\n",
    "    else:\n",
    "        size = 3\n",
    "\n",
    "    # Calculate the formula\n",
    "    size = int(size) // 2\n",
    "    x, y = np.mgrid[-size:size+1, -size:size+1]\n",
    "    normal = 1 / (2.0 * np.pi * sigma**2)\n",
    "    g = normal * np.exp(-((x**2 + y**2) / (2.0*sigma**2)))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_reduction(img):\n",
    "    kernel = gaussian_kernel(1.4)\n",
    "    '''\n",
    "    window_size = kernel.shape[0]\n",
    "    offset = window_size//2\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    # the Filter algorithm\n",
    "    img2 = img.copy()\n",
    "    for i in range(offset, height - offset):\n",
    "        for j in range(offset, width - offset):\n",
    "            new_pixel = 0\n",
    "            for n in range(window_size):\n",
    "                for m in range(window_size):\n",
    "                    a = i - offset + n\n",
    "                    b = j - offset + m\n",
    "                    new_pixel += img[a, b] * kernel[n, m]\n",
    "            img2[i, j] = new_pixel\n",
    "    '''\n",
    "    img = ndimage.filters.convolve(img, kernel)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_calculation(img):\n",
    "    Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
    "    Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=np.float32)\n",
    "\n",
    "    Ix = ndimage.filters.convolve(img, Kx)\n",
    "    Iy = ndimage.filters.convolve(img, Ky)\n",
    "\n",
    "    G = np.hypot(Ix, Iy)\n",
    "    G = G / G.max() * 255\n",
    "    theta = np.arctan2(Iy, Ix)\n",
    "\n",
    "    G = G.astype(int)\n",
    "    return G, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(img, theta):\n",
    "    height, width = img.shape\n",
    "    out = np.zeros((height, width), dtype=int)\n",
    "    # Change from radian to degree\n",
    "    angle = theta * 180 / np.pi\n",
    "    angle[angle < 0] += 180\n",
    "\n",
    "    for i in range(1, height-1):\n",
    "        for j in range(1, width-1):\n",
    "            point_1 = 255\n",
    "            point_2 = 255\n",
    "\n",
    "            # Angle 0°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (east and west) directions\n",
    "            if (0 <= angle[i, j] < 22.5) or (157.5 <= angle[i, j] <= 180):\n",
    "                point_1 = img[i, j-1]\n",
    "                point_2 = img[i, j+1]\n",
    "            # Angle 45°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (north east and south west) directions.\n",
    "            elif 22.5 <= angle[i, j] < 67.5:\n",
    "                point_1 = img[i-1, j+1]\n",
    "                point_2 = img[i+1, j-1]\n",
    "            # Angle 90°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (north and south) directions.\n",
    "            elif 67.5 <= angle[i, j] < 112.5:\n",
    "                point_1 = img[i-1, j]\n",
    "                point_2 = img[i+1, j]\n",
    "            # Angle 135°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (north west and south-east) directions.\n",
    "            elif 112.5 <= angle[i, j] < 157.5:\n",
    "                point_1 = img[i-1, j-1]\n",
    "                point_2 = img[i+1, j+1]\n",
    "\n",
    "            # if the pixel's value is the maximum then update the out, otherwise leave it with value = 0\n",
    "            if (img[i, j] >= point_1) and (img[i, j] >= point_2):\n",
    "                out[i, j] = img[i, j]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_thresholding(img, low_threshold=2, high_threshold=25):\n",
    "    # define the fixed values of the pixels\n",
    "    weak = 25\n",
    "    strong = 255\n",
    "\n",
    "    # extract the indices of the pixels per condition\n",
    "    strong_i, strong_j = np.where(img >= high_threshold)\n",
    "    weak_i, weak_j = np.where((low_threshold <= img) & (img <= high_threshold))\n",
    "    irrelevant_i, irrelevant_j = np.where(img < low_threshold)\n",
    "\n",
    "    # update the indices with the corresponding pixel value\n",
    "    img[strong_i, strong_j] = strong\n",
    "    img[weak_i, weak_j] = weak\n",
    "    img[irrelevant_i, irrelevant_j] = 0\n",
    "\n",
    "    return img, weak, strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hysteresis_edge_tracking(img, weak, strong):\n",
    "    height, width = img.shape\n",
    "    # Get the indices of the weak pixels\n",
    "    weak_i, weak_j = np.where(img == weak)\n",
    "    for (i, j) in zip(weak_i, weak_j):\n",
    "        if i == 0 or j == 0 or i == height - 1 or j == width - 1:\n",
    "            continue\n",
    "        # Check if any of the  8-connected neighborhood pixels is a strong pixel\n",
    "        if np.any(np.where(img[i-1:i+2, j-1:j+2] == strong)):\n",
    "            img[i, j] = strong\n",
    "        # If not, then suppress the weak pixel\n",
    "        else:\n",
    "            img[i, j] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function, to reduce the redundant\n",
    "# plotting code\n",
    "def plotting(img, fig_num, title):\n",
    "    plt.figure(fig_num)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges_canny(img, low_threshold=2, high_threshold=50):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        :param img: np.ndarray((height, width)), gray-image\n",
    "        :param low_threshold: an integer\n",
    "        :param high_threshold: an integer\n",
    "    :return: edges image\n",
    "    \"\"\"\n",
    "    img = img.copy()\n",
    "\n",
    "    # 1. Noise reduction\n",
    "    # using Gaussian Smoothing Kernel\n",
    "    img = noise_reduction(img)\n",
    "    #plotting(img, 1, 'Gaussian Filter')\n",
    "\n",
    "    # 2. Gradient Calculations\n",
    "    # using Sobel kernels\n",
    "    img, theta = gradient_calculation(img)\n",
    "    #plotting(img, 2, 'Sobel Filter (G)')\n",
    "\n",
    "    # 3. Non-Maximum Suppression\n",
    "    img = non_max_suppression(img, theta)\n",
    "    #plotting(img, 3, 'Non-Maximum Suppression')\n",
    "\n",
    "    # 4. Double Thresholding\n",
    "    img, weak, strong = double_thresholding(img, low_threshold, high_threshold)\n",
    "    #plotting(img, 4, 'Double Thresholding')\n",
    "\n",
    "    # 5. Edge Tracking by Hysteresis\n",
    "    img = hysteresis_edge_tracking(img, weak, strong)\n",
    "    #plotting(img, 5, 'Edge Tracking by Hysteresis')\n",
    "\n",
    "    #plt.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(img, kernel_size, width, height):\n",
    "    # You should implement Gaussian Noise Removal Here\n",
    "    #Mean_filter\n",
    "    #height = img.shape(0)\n",
    "    #width = img.shape(1)\n",
    "    final_image = img.copy()\n",
    "    mask_one_dim = math.sqrt(kernel_size)\n",
    "    offset = int(mask_one_dim // 2)\n",
    "    for i in range(offset, height - offset):\n",
    "        for j in range(offset, width - offset):\n",
    "            sum = 0\n",
    "            for r in range(i - offset, i + offset + 1):\n",
    "                for c in range(j - offset, j + offset + 1):\n",
    "                    sum += img[r][c]\n",
    "            final_image[i][j] = sum // kernel_size\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_image(img, vertices, width, height):\n",
    "    # Mask out the pixels outside the region defined in vertices (set the color to black)\n",
    "    #height = img.shape(0)\n",
    "    #width = img.shape(1)\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "            if vertices[i][j] == 0:\n",
    "                img[i][j] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hough_lines(img, lines, path, color=[255, 0, 0], thickness=8):\n",
    "    d = ImageDraw.Draw(img)\n",
    "    for line in lines:\n",
    "        #d.line(line, fill=(255, 255, 255), width=thickness)\n",
    "        d.line(line, fill=(color[0], color[1], color[2]), width=thickness)\n",
    "    #img.save(path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_test():\n",
    "    input_image = read_image('hough_test_1.jpg')\n",
    "    edges = detect_edges_canny(input_image, 2, 50)\n",
    "    lines = hough_transform(edges, 0.3)\n",
    "    draw_hough_lines(Image.open('hough_test_1.jpg'), lines, 'hough_test_1_out.jpg')\n",
    "\n",
    "    input_image = read_image('hough_test_2.jpg')\n",
    "    edges = detect_edges_canny(input_image, 2, 50)\n",
    "    lines = hough_transform(edges)\n",
    "    draw_hough_lines(Image.open('hough_test_2.jpg'), lines, 'hough_test_2_out.jpg')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(img_path):\n",
    "    img = mpimg.imread('lanes_test.jpg')\n",
    "    #img = Image.open(img_path)\n",
    "    #img = img.convert(\"L\")\n",
    "    #img = np.asarray(img, dtype=int)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    return video, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_thresholding(img, low_threshold, high_threshold):\n",
    "    # define the fixed values of the pixels\n",
    "    strong = 255\n",
    "    outimg = np.zeros((img.shape[0],img.shape[1]))\n",
    "\n",
    "    # extract the indices of the pixels per condition for each channel\n",
    "    in_i, in_j, in_ch = np.where((low_threshold <= img & (img <= high_threshold)))\n",
    "    irrelevant_i, irrelevant_j, irrelevant_ch = np.where((img < low_threshold) | (img > high_threshold))\n",
    "\n",
    "    # update the indices with the corresponding pixel value\n",
    "    outimg[in_i, in_j] = strong\n",
    "    outimg[irrelevant_i, irrelevant_j] = 0\n",
    "\n",
    "    return outimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frames(video):\n",
    "    frames = []\n",
    "    width = video.get(3)\n",
    "    height = video.get(4)\n",
    "    success, frame = video.read()\n",
    "    while success:\n",
    "        frames.append(frame)\n",
    "        success, frame = video.read()\n",
    "    return frames, int(width), int(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_video(pathOut, frames, fps, width, height):\n",
    "    size = (width, height)\n",
    "\n",
    "    out = cv2.VideoWriter(pathOut, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pipeline(image, width, height):\n",
    "    # 1. read the image\n",
    "    # 2. convert to HSV\n",
    "    hsv_img = convert_rgb_to_hsv(image)\n",
    "        \n",
    "    # 3. convert to Gray\n",
    "    gray_img = convert_rbg_to_grayscale(image)\n",
    "        \n",
    "    # 4. Threshold HSV for Yellow and White (combine the two results together)\n",
    "        \n",
    "    # 4.1 Threshold HSV for Yellow\n",
    "    lower = np.uint8([10, 0, 200])\n",
    "    upper = np.uint8([40, 255, 255])\n",
    "    yellow_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "    # 4.1 Threshold HSV for White\n",
    "    lower = np.uint8([0, 0, 200])\n",
    "    upper = np.uint8([255, 55, 255])\n",
    "    white_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "    # 4.1 Combine the resuls together\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "\n",
    "    # 5. Mask the gray image using the threshold output from step 4\n",
    "    masked_gray_img = mask_image(gray_img, mask, width, height)\n",
    "\n",
    "    # 6. Apply noise remove (gaussian) to the masked gray image\n",
    "    masked_gray_img = remove_noise(masked_gray_img, 3, width, height)\n",
    "\n",
    "    # 7. use canny detector and fine tune the thresholds (low and high values)\n",
    "    # TODO: masked_gray_img should be of data-type numpy.ndarray\n",
    "    canny_out_img = detect_edges_canny(masked_gray_img, low_threshold=2, high_threshold=50)\n",
    "\n",
    "    # 8. mask the image using the canny detector output\n",
    "    masked_with_canny = mask_image(masked_gray_img, canny_out_img, width, height)\n",
    "\n",
    "    # 9. apply hough transform to find the lanes\n",
    "    lines_for_drawing = hough_transform(masked_with_canny)\n",
    "\n",
    "    # 10. apply the pipeline you developed to the challenge videos\n",
    "    image_with_lines = draw_lines_connected(image, lines_for_drawing)\n",
    "\n",
    "    return image_with_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_pipeline(video_frames, width, height, fps):\n",
    "\n",
    "    new_video_frames = []\n",
    "    i = 1\n",
    "    for frame in video_frames:\n",
    "        new_frame = image_pipeline(frame, width, height)\n",
    "        new_video_frames.append(new_frame)\n",
    "        print(\"{} done!\".format(i))\n",
    "        i+=1\n",
    "        if i == 25:\n",
    "            break\n",
    "\n",
    "    print(\"Length of frames = \", len(new_video_frames))\n",
    "    write_video(\"ChallengeWithLines.mp4\", new_video_frames, 0, width, height)\n",
    "    print(\"Video saved succesffuly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines_connected(img, lines, color=[255, 0, 0], thickness=8):\n",
    "    # This function should draw lines to the images (default color is red and thickness is 8)\n",
    "    image_with_line = img\n",
    "    for line in lines:\n",
    "        point_one = (int(line[0]), int(line[1]))\n",
    "        print(point_one)\n",
    "        point_two = (int(line[2]), int(line[3]))\n",
    "        print(point_two)\n",
    "        image_with_line = cv2.line(image_with_line, point_one, point_two, color, thickness)\n",
    "    cv2.imshow(\"image with lines\",image_with_line)\n",
    "    cv2.waitKey(0)\n",
    "    return image_with_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "video, fps = read_video(\"Challenge.mp4\")\n",
    "video_frames, width, height = get_video_frames(video)\n",
    "video_pipeline(video_frames, width, height, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = read_image('lanes_test.jpg')\n",
    "width = 960\n",
    "height = 540\n",
    "hsv_img = convert_rgb_to_hsv(image)\n",
    "        \n",
    "# 3. convert to Gray\n",
    "gray_img = convert_rbg_to_grayscale(image)\n",
    "        \n",
    "# 4. Threshold HSV for Yellow and White (combine the two results together)\n",
    "        \n",
    "# 4.1 Threshold HSV for Yellow\n",
    "lower = np.uint8([10, 0, 200])\n",
    "upper = np.uint8([40, 255, 255])\n",
    "yellow_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "# 4.1 Threshold HSV for White\n",
    "lower = np.uint8([0, 0, 200])\n",
    "upper = np.uint8([255, 55, 255])\n",
    "white_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "# 4.1 Combine the resuls together\n",
    "mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "\n",
    "# 5. Mask the gray image using the threshold output from step 4\n",
    "masked_gray_img = mask_image(gray_img, mask, width, height)\n",
    "\n",
    "# 6. Apply noise remove (gaussian) to the masked gray image\n",
    "masked_gray_img = remove_noise(masked_gray_img, 3, width, height)\n",
    "\n",
    "# 7. use canny detector and fine tune the thresholds (low and high values)\n",
    "# TODO: masked_gray_img should be of data-type numpy.ndarray\n",
    "canny_out_img = detect_edges_canny(masked_gray_img, low_threshold=2, high_threshold=50)\n",
    "\n",
    "# 8. mask the image using the canny detector output\n",
    "masked_with_canny = mask_image(masked_gray_img, canny_out_img, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Hough transform to find the lanes\n",
    "# Input:\n",
    "#   img - numpy array: binary image containing the edges after applying Canny Detector\n",
    "# Output:\n",
    "#   lines - list of list: list of lines, each line = [x1, y1, x2, y2]\n",
    "def hough_transform(img, accepted_ratio=0.5, rho_step=1, theta_step=1):\n",
    "    print('\\nHough Transform in progress')\n",
    "    # Calculating diagonal length of the image to define the range of the rhos\n",
    "    height, width = img.shape\n",
    "    diagonal_length = round(math.sqrt(height ** 2 + width ** 2))\n",
    "    rhos = np.arange(-diagonal_length, diagonal_length, step=rho_step)\n",
    "\n",
    "    # Setting the thetas and their cosines/sines\n",
    "    thetas = np.arange(-90.0, 90.0, step=theta_step)\n",
    "    cos_thetas = np.cos(np.deg2rad(thetas))\n",
    "    sin_thetas = np.sin(np.deg2rad(thetas))\n",
    "\n",
    "    accumulator = np.zeros((len(rhos), len(thetas)))\n",
    "\n",
    "    edge_pts_ys, edge_pts_xs = np.nonzero(img)\n",
    "    for i in trange(len(edge_pts_xs)):\n",
    "        x = edge_pts_xs[i]\n",
    "        y = edge_pts_ys[i]\n",
    "        for theta_idx in range(len(thetas)):\n",
    "            rho = x * cos_thetas[theta_idx] + y * sin_thetas[theta_idx]\n",
    "            rho_idx = np.argmin(np.abs(rhos - rho))  # find the index of the closest rho to the computed rho\n",
    "            accumulator[rho_idx, theta_idx] += 1\n",
    "\n",
    "    # lines_rhos = []\n",
    "    # lines_thetas = []\n",
    "    lines_rhos_indices, lines_thetas_indices = np.nonzero(accumulator >= accumulator.max() * accepted_ratio)\n",
    "    lines = []\n",
    "    for i in range(len(lines_rhos_indices)):\n",
    "        rho_idx = lines_rhos_indices[i]\n",
    "        rho = rhos[rho_idx]\n",
    "        # lines_rhos.append(rho)\n",
    "\n",
    "        theta_idx = lines_thetas_indices[i]\n",
    "        theta = thetas[theta_idx]\n",
    "        # lines_thetas.append(theta)\n",
    "\n",
    "        a = cos_thetas[theta_idx]\n",
    "        b = sin_thetas[theta_idx]\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 10000 * (-b))\n",
    "        y1 = int(y0 + 10000 * a)\n",
    "        x2 = int(x0 - 10000 * (-b))\n",
    "        y2 = int(y0 - 10000 * a)\n",
    "        lines.append([x1, y1, x2, y2])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1994 [00:00<00:51, 38.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hough Transform in progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1994/1994 [00:51<00:00, 38.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# 9. apply hough transform to find the lanes\n",
    "lines_for_drawing = hough_transform(masked_with_canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 296)\n",
      "(-474, -259)\n",
      "(453, 292)\n",
      "(-462, -279)\n",
      "(454, 292)\n",
      "(-461, -280)\n",
      "(456, 288)\n",
      "(-449, -299)\n",
      "(-140, 740)\n",
      "(744, 121)\n",
      "(-127, 743)\n",
      "(746, 108)\n",
      "(-140, 741)\n",
      "(744, 121)\n",
      "(-152, 738)\n",
      "(742, 134)\n",
      "(-152, 739)\n",
      "(742, 135)\n"
     ]
    }
   ],
   "source": [
    "# 10. apply the pipeline you developed to the challenge videos\n",
    "image = read_image('lanes_test.jpg')\n",
    "image_with_lines = draw_lines_connected(image,lines_for_drawing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
