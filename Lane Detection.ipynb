{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_members_names = ['إسراء ياسر ابوالقاسم',\n",
    "                      'ايمان علاء فرج كامل',\n",
    "                      'منة الله مصطفى مصطفى عوض',\n",
    "                      'منة محيي الدين محمود',\n",
    "                      'ميرنا محمد يسري']\n",
    "team_members_seatnumbers = ['2016170080',\n",
    "                            '2016170113'\n",
    "                            '2016170437',\n",
    "                            '2016170438',\n",
    "                            '2016170450']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from scipy import interpolate\n",
    "from PIL import Image, ImageDraw\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import math \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Conversion and Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rgb_to_grayscale(img):\n",
    "    # This function will do color transform from RGB to Gray\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rgb_to_hsv(img):\n",
    "    # This function will do color transform from RGB to HSV\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_thresholding(img, low_threshold, high_threshold):\n",
    "    # define the fixed values of the pixels\n",
    "    strong = 255\n",
    "    outimg = np.zeros((img.shape[0],img.shape[1]))\n",
    "\n",
    "    # extract the indices of the pixels per condition for each channel\n",
    "    in_i, in_j, in_ch = np.where((low_threshold <= img & (img <= high_threshold)))\n",
    "    irrelevant_i, irrelevant_j, irrelevant_ch = np.where((img < low_threshold) | (img > high_threshold))\n",
    "\n",
    "    # update the indices with the corresponding pixel value\n",
    "    outimg[in_i, in_j] = strong\n",
    "    outimg[irrelevant_i, irrelevant_j] = 0\n",
    "\n",
    "    return outimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(sigma=0.5):\n",
    "    # Specify the kernel size\n",
    "    if sigma > 1:\n",
    "        size = 5\n",
    "    else:\n",
    "        size = 3\n",
    "\n",
    "    # Calculate the formula\n",
    "    size = int(size) // 2\n",
    "    x, y = np.mgrid[-size:size+1, -size:size+1]\n",
    "    normal = 1 / (2.0 * np.pi * sigma**2)\n",
    "    g = normal * np.exp(-((x**2 + y**2) / (2.0*sigma**2)))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(input_arr, weights, c_type='conv', mode='reflect'):\n",
    "    \"\"\"\n",
    "    Two-dimensional convolution.\n",
    "    \n",
    "    The array is convolved with the given kernel.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    input_arr : array_like\n",
    "        Input array to filter.\n",
    "    \n",
    "    weights : array_like\n",
    "        Array of weights(kernel), same number of dimensions as input.\n",
    "        \n",
    "    c_type : {'conv', 'loop'}, optional\n",
    "        The `c_type` parameter determines the implementation of the\n",
    "        convolution.\n",
    "        \n",
    "        'conv'(default)\n",
    "            Use built-in convolve.\n",
    "        \n",
    "        'loop'\n",
    "            Use implemented loop.\n",
    "        \n",
    "    mode : {'constant', 'reflect'}, optional\n",
    "        The `mode` parameter determines how the array borders are\n",
    "        handled.\n",
    "        \n",
    "        'constant'\n",
    "            Pads with a constant value.\n",
    "        \n",
    "        'reflect'(default)\n",
    "            Pads with the reflection of the vector mirrored on the first and last values of the vector along each axis.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    img : ndarray\n",
    "        The result of convolution of `input` with `weights`.\n",
    "    \"\"\"\n",
    "    img = copy.deepcopy(input_arr)\n",
    "    if c_type == 'loop':\n",
    "        window_size = weights.shape[0]\n",
    "        offset = window_size//2\n",
    "        # Pad the working image\n",
    "        padded_img = np.pad(img, offset, mode=mode)\n",
    "        height = padded_img.shape[0]\n",
    "        width = padded_img.shape[1]\n",
    "        img_temp = np.zeros((height, width))\n",
    "        # The filter algorithm\n",
    "        for i in range(offset, height - offset):\n",
    "            for j in range(offset, width - offset):\n",
    "                img_temp[i, j] = np.sum(np.multiply(padded_img[i-offset: i+offset+1, j-offset: j+offset+1], weights))\n",
    "        img = img_temp[offset:height-offset, offset:width-offset]    \n",
    "    else:\n",
    "        img = ndimage.filters.convolve(input_arr, weights, mode=mode)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_reduction(img, c_type='conv', mode='reflect'):\n",
    "    kernel = gaussian_kernel(1.4)\n",
    "    return convolve(img, kernel, c_type=c_type, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_calculation(img, c_type='conv', mode='reflect'):\n",
    "    Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
    "    Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=np.float32)\n",
    "    \n",
    "    Ix = convolve(img, Kx, c_type=c_type, mode=mode)\n",
    "    Iy = convolve(img, Ky, c_type=c_type, mode=mode)\n",
    "    \n",
    "    G = np.hypot(Ix, Iy)\n",
    "    G = G / G.max() * 255\n",
    "    theta = np.arctan2(Iy, Ix)\n",
    "\n",
    "    G = G.astype(int)\n",
    "    return G, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(img, theta):\n",
    "    height, width = img.shape\n",
    "    out = np.zeros((height, width), dtype=int)\n",
    "    # Change from radian to degree\n",
    "    angle = theta * 180 / np.pi\n",
    "    angle[angle < 0] += 180\n",
    "\n",
    "    for i in range(1, height-1):\n",
    "        for j in range(1, width-1):\n",
    "            point_1 = 255\n",
    "            point_2 = 255\n",
    "\n",
    "            # Angle 0°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (east and west) directions\n",
    "            if (0 <= angle[i, j] < 22.5) or (157.5 <= angle[i, j] <= 180):\n",
    "                point_1 = img[i, j-1]\n",
    "                point_2 = img[i, j+1]\n",
    "            # Angle 45°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (north east and south west) directions.\n",
    "            elif 22.5 <= angle[i, j] < 67.5:\n",
    "                point_1 = img[i-1, j+1]\n",
    "                point_2 = img[i+1, j-1]\n",
    "            # Angle 90°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (north and south) directions.\n",
    "            elif 67.5 <= angle[i, j] < 112.5:\n",
    "                point_1 = img[i-1, j]\n",
    "                point_2 = img[i+1, j]\n",
    "            # Angle 135°\n",
    "            # gradient magnitude is greater than the magnitudes at pixels in the (north west and south-east) directions.\n",
    "            elif 112.5 <= angle[i, j] < 157.5:\n",
    "                point_1 = img[i-1, j-1]\n",
    "                point_2 = img[i+1, j+1]\n",
    "\n",
    "            # if the pixel's value is the maximum then update the out, otherwise leave it with value = 0\n",
    "            if (img[i, j] >= point_1) and (img[i, j] >= point_2):\n",
    "                out[i, j] = img[i, j]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_thresholding(img, low_threshold=2, high_threshold=25):\n",
    "    # define the fixed values of the pixels\n",
    "    weak = 25\n",
    "    strong = 255\n",
    "\n",
    "    # extract the indices of the pixels per condition\n",
    "    strong_i, strong_j = np.where(img >= high_threshold)\n",
    "    weak_i, weak_j = np.where((low_threshold <= img) & (img <= high_threshold))\n",
    "    irrelevant_i, irrelevant_j = np.where(img < low_threshold)\n",
    "\n",
    "    # update the indices with the corresponding pixel value\n",
    "    img[strong_i, strong_j] = strong\n",
    "    img[weak_i, weak_j] = weak\n",
    "    img[irrelevant_i, irrelevant_j] = 0\n",
    "\n",
    "    return img, weak, strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hysteresis_edge_tracking(img, weak, strong):\n",
    "    height, width = img.shape\n",
    "    # Get the indices of the weak pixels\n",
    "    weak_i, weak_j = np.where(img == weak)\n",
    "    for (i, j) in zip(weak_i, weak_j):\n",
    "        if i == 0 or j == 0 or i == height - 1 or j == width - 1:\n",
    "            continue\n",
    "        # Check if any of the  8-connected neighborhood pixels is a strong pixel\n",
    "        if np.any(np.where(img[i-1:i+2, j-1:j+2] == strong)):\n",
    "            img[i, j] = strong\n",
    "        # If not, then suppress the weak pixel\n",
    "        else:\n",
    "            img[i, j] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function, to reduce the redundant\n",
    "# plotting code\n",
    "def plotting(img, fig_num, title):\n",
    "    plt.figure(fig_num)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges_canny(img, low_threshold=2, high_threshold=50, c_type='conv', mode='reflect'):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        :param img: np.ndarray((height, width)), gray-image\n",
    "        :param low_threshold: an integer\n",
    "        :param high_threshold: an integer\n",
    "    :return: edges image\n",
    "    \"\"\"\n",
    "    img = img.copy()\n",
    "\n",
    "    # 1. Noise reduction\n",
    "    # using Gaussian Smoothing Kernel\n",
    "    img = noise_reduction(img, c_type=c_type, mode=mode)\n",
    "    plotting(img, 1, 'Gaussian Filter')\n",
    "\n",
    "    # 2. Gradient Calculations\n",
    "    # using Sobel kernels\n",
    "    img, theta = gradient_calculation(img, c_type=c_type, mode=mode)\n",
    "    plotting(img, 2, 'Sobel Filter (G)')\n",
    "\n",
    "    # 3. Non-Maximum Suppression\n",
    "    img = non_max_suppression(img, theta)\n",
    "    plotting(img, 3, 'Non-Maximum Suppression')\n",
    "\n",
    "    # 4. Double Thresholding\n",
    "    img, weak, strong = double_thresholding(img, low_threshold, high_threshold)\n",
    "    plotting(img, 4, 'Double Thresholding')\n",
    "\n",
    "    # 5. Edge Tracking by Hysteresis\n",
    "    img = hysteresis_edge_tracking(img, weak, strong)\n",
    "    plotting(img, 5, 'Edge Tracking by Hysteresis')\n",
    "\n",
    "    plt.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Guassian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(img, kernel_size, width, height):\n",
    "    # You should implement Gaussian Noise Removal Here\n",
    "    #Mean_filter\n",
    "    #height = img.shape(0)\n",
    "    #width = img.shape(1)\n",
    "    final_image = img.copy()\n",
    "    mask_one_dim = math.sqrt(kernel_size)\n",
    "    offset = int(mask_one_dim // 2)\n",
    "    for i in range(offset, height - offset):\n",
    "        for j in range(offset, width - offset):\n",
    "            sum = 0\n",
    "            for r in range(i - offset, i + offset + 1):\n",
    "                for c in range(j - offset, j + offset + 1):\n",
    "                    sum += img[r][c]\n",
    "            final_image[i][j] = sum // kernel_size\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_image(img, vertices, width, height):\n",
    "    out_img = img.copy();\n",
    "    # Mask out the pixels outside the region defined in vertices (set the color to black)\n",
    "    #height = img.shape(0)\n",
    "    #width = img.shape(1)\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "            if vertices[i][j] == 0:\n",
    "                out_img[i][j] = 0\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Hough transform to find the lanes\n",
    "# Input:\n",
    "#   img - numpy array: binary image containing the edges after applying Canny Detector\n",
    "# Output:\n",
    "#   lines - list of list: list of lines, each line = [x1, y1, x2, y2]\n",
    "def hough_transform(img, accepted_ratio=0.2, rho_step=1, theta_step=1):\n",
    "    print('\\nHough Transform in progress')\n",
    "    # Calculating diagonal length of the image to define the range of the rhos\n",
    "    height, width = img.shape\n",
    "    diagonal_length = round(math.sqrt(height ** 2 + width ** 2))\n",
    "    rhos = np.arange(-diagonal_length, diagonal_length, step=rho_step)\n",
    "\n",
    "    # Setting the thetas and their cosines/sines\n",
    "    thetas = np.arange(-90.0, 90.0, step=theta_step)\n",
    "    cos_thetas = np.cos(np.deg2rad(thetas))\n",
    "    sin_thetas = np.sin(np.deg2rad(thetas))\n",
    "\n",
    "    accumulator = np.zeros((len(rhos), len(thetas)))\n",
    "\n",
    "    edge_pts_ys, edge_pts_xs = np.nonzero(img)\n",
    "    for i in trange(len(edge_pts_xs)):\n",
    "        x = edge_pts_xs[i]\n",
    "        y = edge_pts_ys[i]\n",
    "        for theta_idx in range(len(thetas)):\n",
    "            rho = x * cos_thetas[theta_idx] + y * sin_thetas[theta_idx]\n",
    "            rho_idx = np.argmin(np.abs(rhos - rho))  # find the index of the closest rho to the computed rho\n",
    "            accumulator[rho_idx, theta_idx] += 1\n",
    "\n",
    "    # lines_rhos = []\n",
    "    # lines_thetas = []\n",
    "    lines_rhos_indices, lines_thetas_indices = np.nonzero(accumulator >= accumulator.max() * accepted_ratio)\n",
    "    lines = []\n",
    "    for i in range(len(lines_rhos_indices)):\n",
    "        rho_idx = lines_rhos_indices[i]\n",
    "        rho = rhos[rho_idx]\n",
    "        # lines_rhos.append(rho)\n",
    "\n",
    "        theta_idx = lines_thetas_indices[i]\n",
    "        theta = thetas[theta_idx]\n",
    "        # lines_thetas.append(theta)\n",
    "\n",
    "        a = cos_thetas[theta_idx]\n",
    "        b = sin_thetas[theta_idx]\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 10000 * (-b))\n",
    "        y1 = int(y0 + 10000 * a)\n",
    "        x2 = int(x0 - 10000 * (-b))\n",
    "        y2 = int(y0 - 10000 * a)\n",
    "        lines.append([x1, y1, x2, y2])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hough_lines(img, lines, path, color=[255, 0, 0], thickness=8):\n",
    "    d = ImageDraw.Draw(img)\n",
    "    for line in lines:\n",
    "        #d.line(line, fill=(255, 255, 255), width=thickness)\n",
    "        d.line(line, fill=(color[0], color[1], color[2]), width=thickness)\n",
    "    #img.save(path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_test():\n",
    "    input_image = read_image('Images/hough_test_1.jpg')\n",
    "    edges = detect_edges_canny(input_image, 2, 50)\n",
    "    lines = hough_transform(edges, 0.3)\n",
    "    draw_hough_lines(Image.open('Images/hough_test_1.jpg'), lines, 'Images/hough_test_1_out.jpg')\n",
    "\n",
    "    input_image = read_image('Images/hough_test_2.jpg')\n",
    "    edges = detect_edges_canny(input_image, 2, 50)\n",
    "    lines = hough_transform(edges)\n",
    "    draw_hough_lines(Image.open('Images/hough_test_2.jpg'), lines, 'Images/hough_test_2_out.jpg')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Lane Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_length(line):\n",
    "    x1, y1, x2, y2 = line\n",
    "    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = mx + b\n",
    "# This function returns the slope (m) and the intercept (b) of the input line.\n",
    "def get_line_slope_intercept(line):\n",
    "    x1, y1, x2, y2 = line\n",
    "    if x2 - x1 == 0:\n",
    "        return math.inf, 0\n",
    "    slope = (y2 - y1) / (x2 - x1)\n",
    "    # b = y - mx\n",
    "    intercept = y1 - slope * x1\n",
    "    return slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The upper left corner of the image is (0, 0)\n",
    "# X increases left-right\n",
    "# Y increases top-down\n",
    "# Left line: as Y increases, X decreases, so it has a negative slope\n",
    "# Right line: as Y increase, X increases, so it has a positive slope\n",
    "\n",
    "# Input: a list of lines, where each line = [x1, y1, x2, y2]\n",
    "# Output: avg_of_left_lines, avg_of_right_lines, each is a tuple(avg_slope, avg_intercept)\n",
    "def get_avg_slope_intercept(lines):\n",
    "    right_lines = []\n",
    "    right_lengths = []\n",
    "    left_lines = []\n",
    "    left_lengths = []\n",
    "    for line in lines:\n",
    "        slope, intercept = get_line_slope_intercept(line)\n",
    "        if slope == math.inf or (slope >= -0.4 and slope <= 0.4):\n",
    "            continue\n",
    "        line_length = get_line_length(line)\n",
    "        if slope < 0: # left line\n",
    "            left_lines.append([slope, intercept])\n",
    "            left_lengths.append(line_length)\n",
    "        else:         # right line\n",
    "            right_lines.append([slope, intercept])\n",
    "            right_lengths.append(line_length)\n",
    "\n",
    "    # Weighted average of all right lines\n",
    "    if len(right_lines) > 0:\n",
    "        avg_of_right_lines = np.dot(right_lengths, right_lines) / np.sum(right_lengths)\n",
    "    else:\n",
    "        avg_of_right_lines = None\n",
    "    \n",
    "    # Weighted average of all left lines \n",
    "    if len(left_lines) > 0:\n",
    "        avg_of_left_lines = np.dot(left_lengths, left_lines) / np.sum(left_lengths)\n",
    "    else:\n",
    "        avg_of_left_lines = None\n",
    "    \n",
    "    return avg_of_right_lines, avg_of_left_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: y1, y2, line in the form (slope, intercept)\n",
    "# Output: line in the form [x1, y1, x2, y2]\n",
    "# y = mx + b, x = (y - b) / m\n",
    "def get_line_endpoints(y1, y2, line):\n",
    "    if line is None:\n",
    "        return None\n",
    "    slope, intercept = line\n",
    "    x1 = int((y1 - intercept) / slope)\n",
    "    y1 = int(y1)\n",
    "    x2 = int((y2 - intercept) / slope)\n",
    "    y2 = int(y2)\n",
    "    return [x1, y1, x2, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hough returns a lot of lines for one lane line, so we average them to have one line per lane line.\n",
    "def get_lane_lines(img, lines):\n",
    "    avg_of_left_lines, avg_of_right_lines = get_avg_slope_intercept(lines)\n",
    "    y1 = img.shape[0] \n",
    "    y2 = img.shape[0] * 0.59\n",
    "    left_lane = get_line_endpoints(y1, y2, avg_of_left_lines)\n",
    "    right_lane = get_line_endpoints(y1, y2, avg_of_right_lines)\n",
    "    return left_lane, right_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines_connected(img, hough_lines, color=[0, 0, 255], thickness=8):\n",
    "    # This function should draw lines to the images (default color is red and thickness is 8)\n",
    "    lane_lines = get_lane_lines(img, hough_lines)\n",
    "    #lane_lines = hough_lines\n",
    "    lines_image = np.zeros_like(img)\n",
    "    for line in lane_lines:\n",
    "        if line is None:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = line\n",
    "        point_one = (line[0], line[1])\n",
    "        point_two = (line[2], line[3])\n",
    "        cv2.line(lines_image, point_one, point_two, color, thickness)\n",
    "    final_image = cv2.addWeighted(img, 0.8, lines_image, beta=0.95, gamma=0)\n",
    "    cv2.imshow(\"image with lines\", final_image)\n",
    "    cv2.waitKey(0)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [1, 2]\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(img_path):\n",
    "    #img = Image.open(img_path)\n",
    "    #img = img.convert(\"L\")\n",
    "    #img = np.asarray(img, dtype=int)\n",
    "    return mpimg.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    return video, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frames(video):\n",
    "    frames = []\n",
    "    width = video.get(3)\n",
    "    height = video.get(4)\n",
    "    success, frame = video.read()\n",
    "    while success:\n",
    "        frames.append(frame)\n",
    "        success, frame = video.read()\n",
    "    return frames, int(width), int(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_video(pathOut, frames, fps, width, height):\n",
    "    size = (width, height)\n",
    "\n",
    "    out = cv2.VideoWriter(pathOut, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pipeline(image, width, height):\n",
    "    original_image = copy.deepcopy(image)\n",
    "    \n",
    "    # 2. convert to HSV\n",
    "    hsv_img = convert_rgb_to_hsv(image)\n",
    "\n",
    "    # 3. convert to Gray\n",
    "    gray_img = convert_rgb_to_grayscale(image)\n",
    "\n",
    "    # 4. Threshold HSV for Yellow and White (combine the two results together)\n",
    "\n",
    "    # 4.1 Threshold HSV for Yellow\n",
    "    # lower = np.uint8([10, 0, 200])\n",
    "    # upper = np.uint8([40, 255, 255])\n",
    "    lower = np.uint8([10, 0, 100])\n",
    "    upper = np.uint8([40, 255, 255])\n",
    "    yellow_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "    # 4.1 Threshold HSV for White\n",
    "    # lower = np.uint8([0, 0, 200])\n",
    "    # upper = np.uint8([255, 55, 255])\n",
    "    lower = np.uint8([0, 200, 0])\n",
    "    upper = np.uint8([200, 255, 255])\n",
    "    white_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "    # 4.1 Combine the resuls together\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "\n",
    "    # 5. Mask the gray image using the threshold output from step 4\n",
    "    masked_gray_img = mask_image(gray_img, mask, width, height)\n",
    "\n",
    "    # 6. Apply noise remove (gaussian) to the masked gray image\n",
    "    masked_gray_img_no_noise = remove_noise(masked_gray_img, 3, width, height)\n",
    "\n",
    "    # 7. use canny detector and fine tune the thresholds (low and high values)\n",
    "    # TODO: masked_gray_img should be of data-type numpy.ndarray\n",
    "    canny_out_img = detect_edges_canny(masked_gray_img_no_noise, low_threshold=10, high_threshold=50)\n",
    "\n",
    "    # 8. mask the image using the canny detector output\n",
    "    masked_with_canny = mask_image(masked_gray_img_no_noise, canny_out_img, width, height)\n",
    "\n",
    "   # 9. apply hough transform to find the lanes\n",
    "    hough_lines = hough_transform(masked_with_canny)\n",
    "\n",
    "   # 10. apply the pipeline you developed to the challenge videos\n",
    "    image_with_lines = draw_lines_connected(original_image, hough_lines)\n",
    "\n",
    "    return image_with_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_pipeline(video_frames, width, height, fps, name):\n",
    "\n",
    "    new_video_frames = []\n",
    "    i = 1\n",
    "    for frame in video_frames:\n",
    "        new_frame = image_pipeline(frame, width, height)\n",
    "        new_video_frames.append(new_frame)\n",
    "        print(\"{} done!\".format(i))\n",
    "        i+=1\n",
    "        if i == 25:\n",
    "            break\n",
    "\n",
    "    print(\"Length of frames = \", len(new_video_frames))\n",
    "    write_video('Videos/' + name + \" Output.mp4\", new_video_frames, 0, width, height)\n",
    "    print(\"Video saved succesffuly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAIN\n",
    "video, fps = read_video(\"Videos/Yello Lane.mp4\")\n",
    "video_frames, width, height = get_video_frames(video)\n",
    "video_pipeline(video_frames, width, height, fps, \"Yellow Lane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = read_image('Images/white_lane2.jpg')\n",
    "video, fps = read_video(\"Videos/Yello Lane.mp4\")\n",
    "video_frames, width, height = get_video_frames(video)\n",
    "image = video_frames[0]\n",
    "width = image.shape[1]\n",
    "height = image.shape[0]\n",
    "original_image = image\n",
    "\n",
    "hsv_img = convert_rgb_to_hsv(image)\n",
    "        \n",
    "# 3. convert to Gray\n",
    "gray_img = convert_rgb_to_grayscale(image)\n",
    "        \n",
    "# 4. Threshold HSV for Yellow and White (combine the two results together)\n",
    "        \n",
    "# 4.1 Threshold HSV for Yellow\n",
    "# lower = np.uint8([10, 0, 200])\n",
    "# upper = np.uint8([40, 255, 255])\n",
    "lower = np.uint8([10, 0, 100])\n",
    "upper = np.uint8([40, 255, 255])\n",
    "yellow_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "# 4.1 Threshold HSV for White\n",
    "# lower = np.uint8([0, 0, 200])\n",
    "# upper = np.uint8([255, 55, 255])\n",
    "lower = np.uint8([0, 200, 0])\n",
    "upper = np.uint8([200, 255, 255])\n",
    "white_mask = color_thresholding(hsv_img, lower, upper)\n",
    "\n",
    "# 4.1 Combine the resuls together\n",
    "mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "\n",
    "# 5. Mask the gray image using the threshold output from step 4\n",
    "masked_gray_img = mask_image(gray_img, mask, width, height)\n",
    "\n",
    "# 6. Apply noise remove (gaussian) to the masked gray image\n",
    "masked_gray_img_no_noise = remove_noise(masked_gray_img, 3, width, height)\n",
    "\n",
    "# 7. use canny detector and fine tune the thresholds (low and high values)\n",
    "# TODO: masked_gray_img should be of data-type numpy.ndarray\n",
    "canny_out_img = detect_edges_canny(masked_gray_img_no_noise, low_threshold=10, high_threshold=50)\n",
    "\n",
    "# 8. mask the image using the canny detector output\n",
    "masked_with_canny = mask_image(masked_gray_img_no_noise, canny_out_img, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('yello_mask', yellow_mask)\n",
    "cv2.imshow('white_mask', white_mask)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('gray_img', gray_img)\n",
    "cv2.imshow('masked_img', masked_gray_img)\n",
    "cv2.imshow('Diff between gray and masked gray', gray_img - masked_gray_img)\n",
    "cv2.imshow('masked_img_no_noise', masked_gray_img_no_noise)\n",
    "cv2.imshow('masked_with_canny', masked_with_canny)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. apply hough transform to find the lanes\n",
    "max_row = int(masked_with_canny.shape[0] * 0.6)\n",
    "left_min_col = 0\n",
    "left_max_col = int(masked_with_canny.shape[1] * 0.1)\n",
    "right_min_col = int(masked_with_canny.shape[1] * 0.9)\n",
    "right_max_col = int(masked_with_canny.shape[1])\n",
    "for col in range(masked_with_canny.shape[1]):\n",
    "    for row in range(max_row):\n",
    "        masked_with_canny[row][col] = 0\n",
    "for col in range(left_min_col, left_max_col):\n",
    "    for row in range(masked_with_canny.shape[0]):\n",
    "        masked_with_canny[row][col] = 0\n",
    "for col in range(right_min_col, right_max_col):\n",
    "    for row in range(masked_with_canny.shape[0]):\n",
    "        masked_with_canny[row][col] = 0\n",
    "hough_lines = hough_transform(masked_with_canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. apply the pipeline you developed to the challenge videos\n",
    "image_with_lines = draw_lines_connected(original_image, hough_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('g', masked_with_canny)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
